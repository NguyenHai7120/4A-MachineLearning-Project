{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load some useful libraries for data loading and data visualization in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_DataSet(name, data_location = \"data/\"):\n",
    "    return pd.read_csv(data_location + name + \".txt\", sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "path = \"\"\n",
    "data_location = \"data/\"\n",
    "rain = Load_DataSet(\"rain_project\", data_location = path + data_location)\n",
    "# Let's take a look at the data\n",
    "rain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**:\n",
    "\n",
    "In this database, we realise that the qualitative variables including \"Id\", \"date\", \"rain_class\". \n",
    "\n",
    "The other variables are considered quantitative including \"ff\",\"t\", \"td\", \"hu\", \"dd\", \"precip\", \"ws_arome\", \"p3031_arome\", \"u10_arome\", \"v10_arome\", \"t2m_arome\", \"d2m_arome\", \"r_arome\", \"tp_arome\", \"msl_arome\", \"rain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date to month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the column \"date\" into \"month\" to obtain the new data\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "rain[\"date\"] = pd.to_datetime(rain[\"date\"]).dt.month\n",
    "rain = rain.rename(columns= {\"date\":\"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(rain.columns)\n",
    "num_var = names[2:-1]\n",
    "qual_var = [names[i] for i in [0,1,-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithm transformation ($\\log(\\cdot + 1)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_log = rain.copy()\n",
    "\n",
    "rain_log[\"precip\"] = np.log(rain_log[\"precip\"] + 1)\n",
    "rain_log[\"tp_arome\"] = np.log(rain_log[\"tp_arome\"] + 1)\n",
    "rain_log[\"rain_log\"] = np.log(rain_log[\"rain\"] + 1)\n",
    "\n",
    "rain_log.rename(columns = {'precip':'precip_log', 'tp_arome':'tp_arome_log'}, inplace = True)\n",
    "\n",
    "# num_var += [\"rain_log\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_class = pd.get_dummies(rain, columns =  ['month'])\n",
    "rain_log_class = pd.get_dummies(rain_log, columns =  ['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitingData(train_set_rate = .8, random = False):\n",
    "    if not(random):\n",
    "        limit_train_test_set = ceil(train_set_rate*rain.shape[0])\n",
    "\n",
    "        rain_train = rain.iloc[limit_train_test_set:, :]\n",
    "        rain_test = rain.iloc[:limit_train_test_set, :]\n",
    "    \n",
    "    else:\n",
    "        rain_train = rain.sample(frac = train_set_rate)\n",
    "        rain_test = rain.drop(rain_train.index)\n",
    "    return (rain_train, rain_test)\n",
    "\n",
    "train_set_rate = .8 # 80 %\n",
    "rain_train, rain_test = SplitingData(train_set_rate, random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain_train.head())\n",
    "print(rain_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain_test.head())\n",
    "print(rain_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaR = PCA()\n",
    "loadingR = pd.DataFrame(scale(rain[num_var]), columns = rain[num_var].columns)\n",
    "pca_DataSet = pcaR.fit(loadingR).transform(loadingR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "x = np.arange(pcaR.explained_variance_ratio_.size)\n",
    "plt.bar(x, pcaR.explained_variance_ratio_*100)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "x = np.arange(pcaR.explained_variance_ratio_.size)\n",
    "plt.bar(x, pcaR.explained_variance_ratio_.cumsum()*100)\n",
    "plt.plot(x, np.zeros(x.shape)+95, color  =\"red\")\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative summation of explained variance (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_PCA_components = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_DataSet = pd.DataFrame(pca_DataSet)\n",
    "pca_DataSet[\"rain_class\"] = rain[\"rain_class\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_DataSet.iloc[:,0:nb_PCA_components].plot(kind = \"box\", figsize = (15, 6) )\n",
    "plt.xlabel('First %d-th principal components' % nb_PCA_components)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_DataSet.plot.scatter(x=0, y=1, c=\"rain_class\", cmap=\"viridis\", figsize = (10, 10))\n",
    "plt.title('Individuals factor map - PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1 = pcaR.components_[0] * np.sqrt(pcaR.explained_variance_[0])\n",
    "coord2 = pcaR.components_[1] * np.sqrt(pcaR.explained_variance_[1])\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1, coord2, loadingR.columns):\n",
    "    plt.text(i, j, nom)\n",
    "    plt.arrow(0, 0, i, j, color = 'r', width = 0.0001)\n",
    "plt.axis((-1, 1, -1, 1))\n",
    "#Cercle\n",
    "c = plt.Circle((0, 0), radius = 1, color = 'b', fill = False)\n",
    "ax.add_patch(c)\n",
    "plt.title('Variables factor map - PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_DataSet(df, name, data_location = \"data/\"):\n",
    "    df.to_csv(data_location + name + \".txt\", sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_DataSet(rain_train, \"train_set\")\n",
    "Save_DataSet(rain_test, \"test_set\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0650c59a78a128c748f8aadfab5692cc08be5aacb695e9a8f2efcdc6dbedda40"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
