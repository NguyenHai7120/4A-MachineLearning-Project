{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:MASS':\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(MASS)\n",
    "library(nnet)\n",
    "library(caret)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "train_set = read.delim(\"data/train_set.txt\", sep = \" \")\n",
    "test_set = read.delim(\"data/test_set.txt\", sep = \" \")\n",
    "\n",
    "train_set[\"rain\"] = NULL\n",
    "train_set[\"rain_log\"] = NULL\n",
    "\n",
    "test_set[\"rain\"] = NULL\n",
    "test_set[\"rain_log\"] = NULL\n",
    "\n",
    "# WE WILL DELETE ALL MONTH VARIABLES\n",
    "month_names = paste(\"month\", 2:12, sep = \"\")\n",
    "train_set[, month_names] = NULL\n",
    "test_set[, month_names] = NULL\n",
    "\n",
    "train_set[,\"rain_class\"] = as.factor(train_set[,\"rain_class\"])\n",
    "test_set[,\"rain_class\"] = as.factor(test_set[,\"rain_class\"])\n",
    "\n",
    "n_train = nrow(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'ff'</li><li>'t'</li><li>'td'</li><li>'hu'</li><li>'dd'</li><li>'precip_log'</li><li>'ws_arome'</li><li>'p3031_arome'</li><li>'u10_arome'</li><li>'v10_arome'</li><li>'t2m_arome'</li><li>'d2m_arome'</li><li>'r_arome'</li><li>'tp_arome_log'</li><li>'msl_arome'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ff'\n",
       "\\item 't'\n",
       "\\item 'td'\n",
       "\\item 'hu'\n",
       "\\item 'dd'\n",
       "\\item 'precip\\_log'\n",
       "\\item 'ws\\_arome'\n",
       "\\item 'p3031\\_arome'\n",
       "\\item 'u10\\_arome'\n",
       "\\item 'v10\\_arome'\n",
       "\\item 't2m\\_arome'\n",
       "\\item 'd2m\\_arome'\n",
       "\\item 'r\\_arome'\n",
       "\\item 'tp\\_arome\\_log'\n",
       "\\item 'msl\\_arome'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ff'\n",
       "2. 't'\n",
       "3. 'td'\n",
       "4. 'hu'\n",
       "5. 'dd'\n",
       "6. 'precip_log'\n",
       "7. 'ws_arome'\n",
       "8. 'p3031_arome'\n",
       "9. 'u10_arome'\n",
       "10. 'v10_arome'\n",
       "11. 't2m_arome'\n",
       "12. 'd2m_arome'\n",
       "13. 'r_arome'\n",
       "14. 'tp_arome_log'\n",
       "15. 'msl_arome'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"ff\"           \"t\"            \"td\"           \"hu\"           \"dd\"          \n",
       " [6] \"precip_log\"   \"ws_arome\"     \"p3031_arome\"  \"u10_arome\"    \"v10_arome\"   \n",
       "[11] \"t2m_arome\"    \"d2m_arome\"    \"r_arome\"      \"tp_arome_log\" \"msl_arome\"   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_var = setdiff(names(train_set), c(\"rain_class\"))\n",
    "exp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "labels_to_num = function(labels){\n",
    "    n = length(labels)\n",
    "    num = rep(0, times = n)\n",
    "    num[labels == 'no_rain'] = 1\n",
    "    num[labels == 'low_rain'] = 2\n",
    "    num[labels == 'high_rain'] = 3\n",
    "    return(num)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_set[, exp_var]\n",
    "x_test = test_set[, exp_var]\n",
    "\n",
    "y_train = as.factor(train_set[,\"rain_class\"])\n",
    "y_test = as.factor(test_set[,\"rain_class\"])\n",
    "\n",
    "y_train_num = labels_to_num(y_train)\n",
    "y_test_num = labels_to_num(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "MAPE = function(y, y_hat){\n",
    "    # y = as.numeric(y)\n",
    "    # y_hat = as.numeric(y_hat)\n",
    "    mape = 100*mean(abs((y - y_hat)/y))\n",
    "    return(mape)\n",
    "}\n",
    "\n",
    "MSE = function(y, y_hat){\n",
    "    mse = mean((y - y_hat)**2)\n",
    "    return(mse)\n",
    "}\n",
    "\n",
    "confusion_matrix = function(pred_class, true_class){\n",
    "    tab = table(pred_class, true_class)\n",
    "    print(\"Confusion matrix\")\n",
    "    print(tab)\n",
    "    acc = sum(diag(tab)) / sum(tab)\n",
    "    print(paste(\"Prediction accuracy : \", acc))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 16</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ff</th><th scope=col>t</th><th scope=col>td</th><th scope=col>hu</th><th scope=col>dd</th><th scope=col>precip_log</th><th scope=col>ws_arome</th><th scope=col>p3031_arome</th><th scope=col>u10_arome</th><th scope=col>v10_arome</th><th scope=col>t2m_arome</th><th scope=col>d2m_arome</th><th scope=col>r_arome</th><th scope=col>tp_arome_log</th><th scope=col>msl_arome</th><th scope=col>rain_class</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-0.08621305</td><td> 1.164777</td><td> 0.9105351</td><td>-0.79823471</td><td> 0.5200537</td><td>-0.82039852</td><td>-0.03659526</td><td> 0.5297853</td><td> 0.8019527</td><td> 0.4007581</td><td> 1.1187027</td><td> 0.9208535</td><td>-0.69899841</td><td>-0.3621343</td><td> 0.1533010</td><td>low_rain </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-0.21529566</td><td>-1.471529</td><td>-1.6613332</td><td>-0.45471837</td><td> 0.6958876</td><td> 0.07889537</td><td>-0.25766440</td><td> 1.3231433</td><td> 0.5568977</td><td>-0.8887086</td><td>-1.5527261</td><td>-1.5824152</td><td> 0.18145591</td><td> 0.3535131</td><td>-0.9054914</td><td>high_rain</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-1.46867996</td><td> 0.129100</td><td>-0.1875101</td><td>-1.05685344</td><td> 0.1290120</td><td>-0.82039852</td><td>-1.31752316</td><td>-0.8278199</td><td>-0.6050438</td><td>-0.6937063</td><td> 0.2219311</td><td>-0.1249160</td><td>-1.14004178</td><td>-0.6698467</td><td> 0.6887159</td><td>no_rain  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 1.02840090</td><td>-1.238485</td><td>-1.4212403</td><td>-0.49103295</td><td> 1.0222052</td><td> 0.26943290</td><td> 0.46462317</td><td> 1.0634977</td><td> 1.1864348</td><td>-0.7170438</td><td>-1.1660485</td><td>-1.3825454</td><td>-0.53032676</td><td> 0.4926930</td><td> 0.8759910</td><td>no_rain  </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-1.46553799</td><td>-1.273800</td><td>-1.2888096</td><td> 0.07576901</td><td>-0.8504800</td><td>-0.61244731</td><td>-1.27793928</td><td>-0.5881897</td><td>-0.4321987</td><td> 0.1073955</td><td>-1.6551375</td><td>-1.7090362</td><td> 0.05194278</td><td>-0.9410006</td><td> 1.8945691</td><td>low_rain </td></tr>\n",
       "\t<tr><th scope=row>8</th><td> 2.36216728</td><td>-1.243795</td><td>-1.3614883</td><td>-0.33792281</td><td>-2.0645970</td><td>-0.82039852</td><td> 1.53127621</td><td>-2.0125623</td><td>-2.3869380</td><td>-1.7343155</td><td>-1.0988396</td><td>-1.2270086</td><td>-0.29023814</td><td>-1.0305921</td><td> 0.4655751</td><td>no_rain  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 16\n",
       "\\begin{tabular}{r|llllllllllllllll}\n",
       "  & ff & t & td & hu & dd & precip\\_log & ws\\_arome & p3031\\_arome & u10\\_arome & v10\\_arome & t2m\\_arome & d2m\\_arome & r\\_arome & tp\\_arome\\_log & msl\\_arome & rain\\_class\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & -0.08621305 &  1.164777 &  0.9105351 & -0.79823471 &  0.5200537 & -0.82039852 & -0.03659526 &  0.5297853 &  0.8019527 &  0.4007581 &  1.1187027 &  0.9208535 & -0.69899841 & -0.3621343 &  0.1533010 & low\\_rain \\\\\n",
       "\t2 & -0.21529566 & -1.471529 & -1.6613332 & -0.45471837 &  0.6958876 &  0.07889537 & -0.25766440 &  1.3231433 &  0.5568977 & -0.8887086 & -1.5527261 & -1.5824152 &  0.18145591 &  0.3535131 & -0.9054914 & high\\_rain\\\\\n",
       "\t4 & -1.46867996 &  0.129100 & -0.1875101 & -1.05685344 &  0.1290120 & -0.82039852 & -1.31752316 & -0.8278199 & -0.6050438 & -0.6937063 &  0.2219311 & -0.1249160 & -1.14004178 & -0.6698467 &  0.6887159 & no\\_rain  \\\\\n",
       "\t5 &  1.02840090 & -1.238485 & -1.4212403 & -0.49103295 &  1.0222052 &  0.26943290 &  0.46462317 &  1.0634977 &  1.1864348 & -0.7170438 & -1.1660485 & -1.3825454 & -0.53032676 &  0.4926930 &  0.8759910 & no\\_rain  \\\\\n",
       "\t6 & -1.46553799 & -1.273800 & -1.2888096 &  0.07576901 & -0.8504800 & -0.61244731 & -1.27793928 & -0.5881897 & -0.4321987 &  0.1073955 & -1.6551375 & -1.7090362 &  0.05194278 & -0.9410006 &  1.8945691 & low\\_rain \\\\\n",
       "\t8 &  2.36216728 & -1.243795 & -1.3614883 & -0.33792281 & -2.0645970 & -0.82039852 &  1.53127621 & -2.0125623 & -2.3869380 & -1.7343155 & -1.0988396 & -1.2270086 & -0.29023814 & -1.0305921 &  0.4655751 & no\\_rain  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 16\n",
       "\n",
       "| <!--/--> | ff &lt;dbl&gt; | t &lt;dbl&gt; | td &lt;dbl&gt; | hu &lt;dbl&gt; | dd &lt;dbl&gt; | precip_log &lt;dbl&gt; | ws_arome &lt;dbl&gt; | p3031_arome &lt;dbl&gt; | u10_arome &lt;dbl&gt; | v10_arome &lt;dbl&gt; | t2m_arome &lt;dbl&gt; | d2m_arome &lt;dbl&gt; | r_arome &lt;dbl&gt; | tp_arome_log &lt;dbl&gt; | msl_arome &lt;dbl&gt; | rain_class &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | -0.08621305 |  1.164777 |  0.9105351 | -0.79823471 |  0.5200537 | -0.82039852 | -0.03659526 |  0.5297853 |  0.8019527 |  0.4007581 |  1.1187027 |  0.9208535 | -0.69899841 | -0.3621343 |  0.1533010 | low_rain  |\n",
       "| 2 | -0.21529566 | -1.471529 | -1.6613332 | -0.45471837 |  0.6958876 |  0.07889537 | -0.25766440 |  1.3231433 |  0.5568977 | -0.8887086 | -1.5527261 | -1.5824152 |  0.18145591 |  0.3535131 | -0.9054914 | high_rain |\n",
       "| 4 | -1.46867996 |  0.129100 | -0.1875101 | -1.05685344 |  0.1290120 | -0.82039852 | -1.31752316 | -0.8278199 | -0.6050438 | -0.6937063 |  0.2219311 | -0.1249160 | -1.14004178 | -0.6698467 |  0.6887159 | no_rain   |\n",
       "| 5 |  1.02840090 | -1.238485 | -1.4212403 | -0.49103295 |  1.0222052 |  0.26943290 |  0.46462317 |  1.0634977 |  1.1864348 | -0.7170438 | -1.1660485 | -1.3825454 | -0.53032676 |  0.4926930 |  0.8759910 | no_rain   |\n",
       "| 6 | -1.46553799 | -1.273800 | -1.2888096 |  0.07576901 | -0.8504800 | -0.61244731 | -1.27793928 | -0.5881897 | -0.4321987 |  0.1073955 | -1.6551375 | -1.7090362 |  0.05194278 | -0.9410006 |  1.8945691 | low_rain  |\n",
       "| 8 |  2.36216728 | -1.243795 | -1.3614883 | -0.33792281 | -2.0645970 | -0.82039852 |  1.53127621 | -2.0125623 | -2.3869380 | -1.7343155 | -1.0988396 | -1.2270086 | -0.29023814 | -1.0305921 |  0.4655751 | no_rain   |\n",
       "\n"
      ],
      "text/plain": [
       "  ff          t         td         hu          dd         precip_log \n",
       "1 -0.08621305  1.164777  0.9105351 -0.79823471  0.5200537 -0.82039852\n",
       "2 -0.21529566 -1.471529 -1.6613332 -0.45471837  0.6958876  0.07889537\n",
       "4 -1.46867996  0.129100 -0.1875101 -1.05685344  0.1290120 -0.82039852\n",
       "5  1.02840090 -1.238485 -1.4212403 -0.49103295  1.0222052  0.26943290\n",
       "6 -1.46553799 -1.273800 -1.2888096  0.07576901 -0.8504800 -0.61244731\n",
       "8  2.36216728 -1.243795 -1.3614883 -0.33792281 -2.0645970 -0.82039852\n",
       "  ws_arome    p3031_arome u10_arome  v10_arome  t2m_arome  d2m_arome \n",
       "1 -0.03659526  0.5297853   0.8019527  0.4007581  1.1187027  0.9208535\n",
       "2 -0.25766440  1.3231433   0.5568977 -0.8887086 -1.5527261 -1.5824152\n",
       "4 -1.31752316 -0.8278199  -0.6050438 -0.6937063  0.2219311 -0.1249160\n",
       "5  0.46462317  1.0634977   1.1864348 -0.7170438 -1.1660485 -1.3825454\n",
       "6 -1.27793928 -0.5881897  -0.4321987  0.1073955 -1.6551375 -1.7090362\n",
       "8  1.53127621 -2.0125623  -2.3869380 -1.7343155 -1.0988396 -1.2270086\n",
       "  r_arome     tp_arome_log msl_arome  rain_class\n",
       "1 -0.69899841 -0.3621343    0.1533010 low_rain  \n",
       "2  0.18145591  0.3535131   -0.9054914 high_rain \n",
       "4 -1.14004178 -0.6698467    0.6887159 no_rain   \n",
       "5 -0.53032676  0.4926930    0.8759910 no_rain   \n",
       "6  0.05194278 -0.9410006    1.8945691 low_rain  \n",
       "8 -0.29023814 -1.0305921    0.4655751 no_rain   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hidden-layer with softmax activation with Entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit a neural network (perceptron) with 5 units in the hidden-layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  98\n",
      "initial  value 622.520775 \n",
      "iter  10 value 502.391423\n",
      "iter  20 value 469.905200\n",
      "iter  30 value 447.343723\n",
      "iter  40 value 431.174709\n",
      "iter  50 value 424.581700\n",
      "iter  60 value 422.384781\n",
      "iter  70 value 421.580571\n",
      "iter  80 value 421.164517\n",
      "iter  90 value 421.003663\n",
      "iter 100 value 420.284055\n",
      "iter 110 value 420.099475\n",
      "iter 120 value 420.066476\n",
      "iter 130 value 420.062730\n",
      "iter 140 value 420.052317\n",
      "iter 150 value 419.746548\n",
      "iter 160 value 418.950353\n",
      "iter 170 value 416.144664\n",
      "iter 180 value 414.910711\n",
      "iter 190 value 413.846650\n",
      "iter 200 value 413.037408\n",
      "iter 210 value 412.384284\n",
      "iter 220 value 411.956885\n",
      "iter 230 value 411.835767\n",
      "iter 240 value 411.637760\n",
      "iter 250 value 409.964685\n",
      "iter 260 value 409.466114\n",
      "iter 270 value 409.285554\n",
      "iter 280 value 409.278453\n",
      "iter 290 value 409.277933\n",
      "final  value 409.277917 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "nnet.class = nnet(rain_class ~ ., data = train_set, size = 5, decay = 0.01, entropy = TRUE, maxit = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$names</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'n'</li><li>'nunits'</li><li>'nconn'</li><li>'conn'</li><li>'nsunits'</li><li>'decay'</li><li>'entropy'</li><li>'softmax'</li><li>'censored'</li><li>'value'</li><li>'wts'</li><li>'convergence'</li><li>'fitted.values'</li><li>'residuals'</li><li>'lev'</li><li>'call'</li><li>'terms'</li><li>'coefnames'</li><li>'xlevels'</li></ol>\n",
       "</dd>\n",
       "\t<dt>$class</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'nnet.formula'</li><li>'nnet'</li></ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$names] \\begin{enumerate*}\n",
       "\\item 'n'\n",
       "\\item 'nunits'\n",
       "\\item 'nconn'\n",
       "\\item 'conn'\n",
       "\\item 'nsunits'\n",
       "\\item 'decay'\n",
       "\\item 'entropy'\n",
       "\\item 'softmax'\n",
       "\\item 'censored'\n",
       "\\item 'value'\n",
       "\\item 'wts'\n",
       "\\item 'convergence'\n",
       "\\item 'fitted.values'\n",
       "\\item 'residuals'\n",
       "\\item 'lev'\n",
       "\\item 'call'\n",
       "\\item 'terms'\n",
       "\\item 'coefnames'\n",
       "\\item 'xlevels'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$class] \\begin{enumerate*}\n",
       "\\item 'nnet.formula'\n",
       "\\item 'nnet'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$names\n",
       ":   1. 'n'\n",
       "2. 'nunits'\n",
       "3. 'nconn'\n",
       "4. 'conn'\n",
       "5. 'nsunits'\n",
       "6. 'decay'\n",
       "7. 'entropy'\n",
       "8. 'softmax'\n",
       "9. 'censored'\n",
       "10. 'value'\n",
       "11. 'wts'\n",
       "12. 'convergence'\n",
       "13. 'fitted.values'\n",
       "14. 'residuals'\n",
       "15. 'lev'\n",
       "16. 'call'\n",
       "17. 'terms'\n",
       "18. 'coefnames'\n",
       "19. 'xlevels'\n",
       "\n",
       "\n",
       "\n",
       "$class\n",
       ":   1. 'nnet.formula'\n",
       "2. 'nnet'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$names\n",
       " [1] \"n\"             \"nunits\"        \"nconn\"         \"conn\"         \n",
       " [5] \"nsunits\"       \"decay\"         \"entropy\"       \"softmax\"      \n",
       " [9] \"censored\"      \"value\"         \"wts\"           \"convergence\"  \n",
       "[13] \"fitted.values\" \"residuals\"     \"lev\"           \"call\"         \n",
       "[17] \"terms\"         \"coefnames\"     \"xlevels\"      \n",
       "\n",
       "$class\n",
       "[1] \"nnet.formula\" \"nnet\"        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes(nnet.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnet.class$entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>high_rain</th><th scope=col>low_rain</th><th scope=col>no_rain</th><th scope=col>max_prob</th><th scope=col>label</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.0967067482</td><td>0.68619222</td><td>0.21710103</td><td>low_rain </td><td>low_rain </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.7293861037</td><td>0.22134533</td><td>0.04926856</td><td>high_rain</td><td>high_rain</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.0318939949</td><td>0.46734392</td><td>0.50076209</td><td>no_rain  </td><td>no_rain  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.4028308245</td><td>0.38680271</td><td>0.21036646</td><td>high_rain</td><td>no_rain  </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.0670736381</td><td>0.59086373</td><td>0.34206263</td><td>low_rain </td><td>low_rain </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0.0006817325</td><td>0.08229994</td><td>0.91701833</td><td>no_rain  </td><td>no_rain  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & high\\_rain & low\\_rain & no\\_rain & max\\_prob & label\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <chr> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 0.0967067482 & 0.68619222 & 0.21710103 & low\\_rain  & low\\_rain \\\\\n",
       "\t2 & 0.7293861037 & 0.22134533 & 0.04926856 & high\\_rain & high\\_rain\\\\\n",
       "\t4 & 0.0318939949 & 0.46734392 & 0.50076209 & no\\_rain   & no\\_rain  \\\\\n",
       "\t5 & 0.4028308245 & 0.38680271 & 0.21036646 & high\\_rain & no\\_rain  \\\\\n",
       "\t6 & 0.0670736381 & 0.59086373 & 0.34206263 & low\\_rain  & low\\_rain \\\\\n",
       "\t8 & 0.0006817325 & 0.08229994 & 0.91701833 & no\\_rain   & no\\_rain  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | high_rain &lt;dbl&gt; | low_rain &lt;dbl&gt; | no_rain &lt;dbl&gt; | max_prob &lt;chr&gt; | label &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 0.0967067482 | 0.68619222 | 0.21710103 | low_rain  | low_rain  |\n",
       "| 2 | 0.7293861037 | 0.22134533 | 0.04926856 | high_rain | high_rain |\n",
       "| 4 | 0.0318939949 | 0.46734392 | 0.50076209 | no_rain   | no_rain   |\n",
       "| 5 | 0.4028308245 | 0.38680271 | 0.21036646 | high_rain | no_rain   |\n",
       "| 6 | 0.0670736381 | 0.59086373 | 0.34206263 | low_rain  | low_rain  |\n",
       "| 8 | 0.0006817325 | 0.08229994 | 0.91701833 | no_rain   | no_rain   |\n",
       "\n"
      ],
      "text/plain": [
       "  high_rain    low_rain   no_rain    max_prob  label    \n",
       "1 0.0967067482 0.68619222 0.21710103 low_rain  low_rain \n",
       "2 0.7293861037 0.22134533 0.04926856 high_rain high_rain\n",
       "4 0.0318939949 0.46734392 0.50076209 no_rain   no_rain  \n",
       "5 0.4028308245 0.38680271 0.21036646 high_rain no_rain  \n",
       "6 0.0670736381 0.59086373 0.34206263 low_rain  low_rain \n",
       "8 0.0006817325 0.08229994 0.91701833 no_rain   no_rain  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnet_train_prediction <- data.frame(nnet.class$fitted.values) %>%\n",
    "    mutate(max_prob = colnames(.)[apply(., 1, which.max)],\n",
    "            label = y_train)\n",
    "head(nnet_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "           Reference\n",
       "Prediction  high_rain low_rain no_rain\n",
       "  high_rain       101       29       7\n",
       "  low_rain         49      171      61\n",
       "  no_rain           5       34      93\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.6636          \n",
       "                 95% CI : (0.6224, 0.7031)\n",
       "    No Information Rate : 0.4255          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.4762          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.004353        \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: high_rain Class: low_rain Class: no_rain\n",
       "Sensitivity                    0.6516          0.7308         0.5776\n",
       "Specificity                    0.9089          0.6519         0.8997\n",
       "Pos Pred Value                 0.7372          0.6085         0.7045\n",
       "Neg Pred Value                 0.8692          0.7658         0.8373\n",
       "Precision                      0.7372          0.6085         0.7045\n",
       "Recall                         0.6516          0.7308         0.5776\n",
       "F1                             0.6918          0.6641         0.6348\n",
       "Prevalence                     0.2818          0.4255         0.2927\n",
       "Detection Rate                 0.1836          0.3109         0.1691\n",
       "Detection Prevalence           0.2491          0.5109         0.2400\n",
       "Balanced Accuracy              0.7802          0.6913         0.7387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(factor(nnet_train_prediction$max_prob),\n",
    "                factor(nnet_train_prediction$label),\n",
    "                mode = \"everything\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "           Reference\n",
       "Prediction  high_rain low_rain no_rain\n",
       "  high_rain        19        8       7\n",
       "  low_rain         11       34      27\n",
       "  no_rain           3       16      13\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.4783          \n",
       "                 95% CI : (0.3926, 0.5649)\n",
       "    No Information Rate : 0.4203          \n",
       "    P-Value [Acc > NIR] : 0.09836         \n",
       "                                          \n",
       "                  Kappa : 0.1884          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.18021         \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: high_rain Class: low_rain Class: no_rain\n",
       "Sensitivity                    0.5758          0.5862         0.2766\n",
       "Specificity                    0.8571          0.5250         0.7912\n",
       "Pos Pred Value                 0.5588          0.4722         0.4062\n",
       "Neg Pred Value                 0.8654          0.6364         0.6792\n",
       "Prevalence                     0.2391          0.4203         0.3406\n",
       "Detection Rate                 0.1377          0.2464         0.0942\n",
       "Detection Prevalence           0.2464          0.5217         0.2319\n",
       "Balanced Accuracy              0.7165          0.5556         0.5339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnet_test_prediction = predict(nnet.class, newdata = test_set, type = \"class\")\n",
    "confusionMatrix(as.factor(nnet_test_prediction), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy is not very accurate. So we need to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "nnet.class.tune = tune.nnet(rain_class ~ ., data = train_set, \n",
    "        size = seq(5, 10, by = 1), decay = c(0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05), entropy = TRUE, maxit = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Performance of `nnet'\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(nnet.class.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$names</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'best.parameters'</li><li>'best.performance'</li><li>'method'</li><li>'nparcomb'</li><li>'train.ind'</li><li>'sampling'</li><li>'performances'</li><li>'best.model'</li></ol>\n",
       "</dd>\n",
       "\t<dt>$class</dt>\n",
       "\t\t<dd>'tune'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$names] \\begin{enumerate*}\n",
       "\\item 'best.parameters'\n",
       "\\item 'best.performance'\n",
       "\\item 'method'\n",
       "\\item 'nparcomb'\n",
       "\\item 'train.ind'\n",
       "\\item 'sampling'\n",
       "\\item 'performances'\n",
       "\\item 'best.model'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$class] 'tune'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$names\n",
       ":   1. 'best.parameters'\n",
       "2. 'best.performance'\n",
       "3. 'method'\n",
       "4. 'nparcomb'\n",
       "5. 'train.ind'\n",
       "6. 'sampling'\n",
       "7. 'performances'\n",
       "8. 'best.model'\n",
       "\n",
       "\n",
       "\n",
       "$class\n",
       ":   'tune'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$names\n",
       "[1] \"best.parameters\"  \"best.performance\" \"method\"           \"nparcomb\"        \n",
       "[5] \"train.ind\"        \"sampling\"         \"performances\"     \"best.model\"      \n",
       "\n",
       "$class\n",
       "[1] \"tune\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes(nnet.class.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>size</th><th scope=col>decay</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>31</th><td>5</td><td>0.05</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & size & decay\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t31 & 5 & 0.05\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 2\n",
       "\n",
       "| <!--/--> | size &lt;dbl&gt; | decay &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 31 | 5 | 0.05 |\n",
       "\n"
      ],
      "text/plain": [
       "   size decay\n",
       "31 5    0.05 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnet.class.tune$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.497454545454545"
      ],
      "text/latex": [
       "0.497454545454545"
      ],
      "text/markdown": [
       "0.497454545454545"
      ],
      "text/plain": [
       "[1] 0.4974545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nnet.class.tune$best.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  98\n",
      "initial  value 698.326931 \n",
      "iter  10 value 496.569445\n",
      "iter  20 value 467.199553\n",
      "iter  30 value 451.539418\n",
      "iter  40 value 439.840133\n",
      "iter  50 value 435.719315\n",
      "iter  60 value 433.154764\n",
      "iter  70 value 432.716582\n",
      "iter  80 value 432.555652\n",
      "iter  90 value 432.516553\n",
      "iter 100 value 432.473510\n",
      "iter 110 value 432.438667\n",
      "final  value 432.438292 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "nnet.class.best = nnet(rain_class ~ ., data = train_set, \n",
    "        size = 5, decay = 0.05, entropy = TRUE, maxit = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "           Reference\n",
       "Prediction  high_rain low_rain no_rain\n",
       "  high_rain        97       31       9\n",
       "  low_rain         47      155      43\n",
       "  no_rain          11       48     109\n",
       "\n",
       "Overall Statistics\n",
       "                                        \n",
       "               Accuracy : 0.6564        \n",
       "                 95% CI : (0.615, 0.696)\n",
       "    No Information Rate : 0.4255        \n",
       "    P-Value [Acc > NIR] : <2e-16        \n",
       "                                        \n",
       "                  Kappa : 0.472         \n",
       "                                        \n",
       " Mcnemar's Test P-Value : 0.289         \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: high_rain Class: low_rain Class: no_rain\n",
       "Sensitivity                    0.6258          0.6624         0.6770\n",
       "Specificity                    0.8987          0.7152         0.8483\n",
       "Pos Pred Value                 0.7080          0.6327         0.6488\n",
       "Neg Pred Value                 0.8596          0.7410         0.8639\n",
       "Precision                      0.7080          0.6327         0.6488\n",
       "Recall                         0.6258          0.6624         0.6770\n",
       "F1                             0.6644          0.6472         0.6626\n",
       "Prevalence                     0.2818          0.4255         0.2927\n",
       "Detection Rate                 0.1764          0.2818         0.1982\n",
       "Detection Prevalence           0.2491          0.4455         0.3055\n",
       "Balanced Accuracy              0.7623          0.6888         0.7627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_prediction <- data.frame(nnet.class.best$fitted.values) %>%\n",
    "    mutate(max_prob = colnames(.)[apply(., 1, which.max)],\n",
    "            label = y_train)\n",
    "\n",
    "confusionMatrix(factor(train_prediction$max_prob),\n",
    "                factor(train_prediction$label),\n",
    "                mode = \"everything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "           Reference\n",
       "Prediction  high_rain low_rain no_rain\n",
       "  high_rain        22        9       8\n",
       "  low_rain          8       31      22\n",
       "  no_rain           3       18      17\n",
       "\n",
       "Overall Statistics\n",
       "                                          \n",
       "               Accuracy : 0.5072          \n",
       "                 95% CI : (0.4209, 0.5933)\n",
       "    No Information Rate : 0.4203          \n",
       "    P-Value [Acc > NIR] : 0.02422         \n",
       "                                          \n",
       "                  Kappa : 0.2452          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.43489         \n",
       "\n",
       "Statistics by Class:\n",
       "\n",
       "                     Class: high_rain Class: low_rain Class: no_rain\n",
       "Sensitivity                    0.6667          0.5345         0.3617\n",
       "Specificity                    0.8381          0.6250         0.7692\n",
       "Pos Pred Value                 0.5641          0.5082         0.4474\n",
       "Neg Pred Value                 0.8889          0.6494         0.7000\n",
       "Prevalence                     0.2391          0.4203         0.3406\n",
       "Detection Rate                 0.1594          0.2246         0.1232\n",
       "Detection Prevalence           0.2826          0.4420         0.2754\n",
       "Balanced Accuracy              0.7524          0.5797         0.5655"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction = predict(nnet.class.best, newdata = test_set, type = \"class\")\n",
    "confusionMatrix(as.factor(test_prediction), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
